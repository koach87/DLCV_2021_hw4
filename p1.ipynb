{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support set means train set\n",
    "# query set means test set\n",
    "episode = 600\n",
    "train_N_way = 5\n",
    "train_K_shot = 1\n",
    "train_N_query = 15\n",
    "\n",
    "val_N_way = 5\n",
    "val_K_shot = 1\n",
    "val_N_query = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenameToPILImage = lambda x: Image.open(x)\n",
    "# mini-Imagenet dataset\n",
    "class MiniDataset(Dataset):\n",
    "    def __init__(self, csv_path, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_df = pd.read_csv(csv_path).set_index(\"id\")\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            filenameToPILImage,\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.data_df.loc[index, \"filename\"]\n",
    "        label = self.data_df.loc[index, \"label\"]\n",
    "        image = self.transform(os.path.join(self.data_dir, path))\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorSampler(Sampler):\n",
    "    def __init__(self, episode_file_path):\n",
    "        episode_df = pd.read_csv(episode_file_path).set_index(\"episode_id\")\n",
    "        self.sampled_sequence = episode_df.values.flatten().tolist()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.sampled_sequence) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sampled_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convnet(nn.Module):\n",
    "    def __init__(self, in_chaneels=3, hid_channels=64, out_channels=64):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv_block(in_chaneels, hid_channels),\n",
    "            conv_block(hid_channels, hid_channels),\n",
    "            conv_block(hid_channels, hid_channels),\n",
    "            conv_block(hid_channels, out_channels),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "def conv_block(in_chaneels, out_channels):\n",
    "    bn = nn.BatchNorm2d(out_channels)\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_chaneels, out_channels, 3, padding=1),\n",
    "        bn,\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1600, 512),\n",
    "            # nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        # self.num_layers = num_layers\n",
    "        # h = [hidden_dim] * (num_layers - 1)\n",
    "        # self.layers = nn.ModuleList(nn.Linear(n, k)\n",
    "        #                             for n, k in zip([input_dim] + h, h + [output_dim]))\n",
    "    def forward(self,  x):\n",
    "        # for i, layer in enumerate(self.layers):\n",
    "        #     x = F.relu(layer(x)) if i < self.num_layers - 1 else layer(x)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = MLP(1600, 512, 1, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_sampler(Sampler):\n",
    "    def __init__(self, csv_path, episode):\n",
    "        data_df = pd.read_csv(csv_path).set_index(\"id\")\n",
    "        clses = data_df['label'].unique()\n",
    "        img_choose = []\n",
    "        self.img_choose = []\n",
    "        for i in range(episode):\n",
    "            choosed_support = []\n",
    "            choosed_query = []\n",
    "\n",
    "            choosed_cls = random.sample(range(len(clses)),train_N_way)\n",
    "            for j in range(train_N_way):\n",
    "                choosed_sq = random.sample(data_df[data_df['label']==clses[choosed_cls[j]]].index.tolist(),train_N_query+train_K_shot)\n",
    "\n",
    "                choosed_query.append(choosed_sq[train_K_shot:])\n",
    "                choosed_support.append(choosed_sq[:train_K_shot])\n",
    "\n",
    "            flat_choosed_query =  [item for sublist in choosed_query for item in sublist]\n",
    "            flat_choosed_support = [item for sublist in choosed_support for item in sublist]\n",
    "            \n",
    "            img_choose.append(flat_choosed_support + flat_choosed_query)\n",
    "\n",
    "        self.img_choose = [item for sublist in img_choose for item in sublist]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self.img_choose) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_choose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv, train_data_dir = 'hw4_data/mini/train.csv', 'hw4_data/mini/train'\n",
    "train_dataset = MiniDataset(train_csv, train_data_dir)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_N_way*(train_N_query + train_K_shot),\n",
    "    pin_memory=False,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    sampler=train_sampler('hw4_data/mini/train.csv',episode)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_csv, val_data_dir = 'hw4_data/mini/val.csv','hw4_data/mini/val'\n",
    "# val_dataset = MiniDataset(val_csv, val_data_dir)\n",
    "# val_loader = DataLoader(\n",
    "#         val_dataset, batch_size=val_N_way * (val_N_query + val_K_shot),\n",
    "#         pin_memory=False, worker_init_fn=worker_init_fn,\n",
    "#         sampler=GeneratorSampler('hw4_data/mini/val_testcase.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_csv, val_data_dir = 'hw4_data/mini/val.csv','hw4_data/mini/val'\n",
    "val_dataset = MiniDataset(val_csv, val_data_dir)\n",
    "val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=val_N_way * (val_N_query + val_K_shot),\n",
    "        pin_memory=False, \n",
    "        worker_init_fn=worker_init_fn,\n",
    "        sampler=train_sampler('hw4_data/mini/val.csv',episode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    # eq 1e-4 cs 1e-3\n",
    "    optimizer = optim.Adam([*model.parameters(),*dist.parameters()], lr=1e-4)\n",
    "    # dist_optimizer = optim.Adam(dist.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # dist_criterion = nn.CrossEntropyLoss()\n",
    "    for ep in range(epoch):\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        episodic_acc = []\n",
    "        model.train()\n",
    "        for i, (data, target) in enumerate(tqdm(train_loader)):\n",
    "            # if(i==1):break\n",
    "            # split data into support and query data\n",
    "            support_input = data[:train_N_way * train_K_shot,:,:,:]\n",
    "            query_input   = data[train_N_way * train_K_shot:,:,:,:]\n",
    "\n",
    "            # create the relative label (0 ~ N_way-1) for query data\n",
    "            label_encoder = {target[i * train_K_shot] : i for i in range(train_N_way)}\n",
    "            query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[train_N_way * train_K_shot:]])\n",
    "\n",
    "            # TODO: extract the feature of support and query data\n",
    "            # shape:torch.Size([N-way*K-shot, 1600]) torch.Size([N-way*N-query, 1600])\n",
    "            support_feature = model(support_input.to(device))\n",
    "            query_feature = model(query_input.to(device))\n",
    "            support_feature = support_feature.view(train_N_way,train_K_shot,1600).mean(dim=1)\n",
    "\n",
    "            # TODO: calculate the prototype for each class according to its support data\n",
    "            # ref:https://discuss.pytorch.org/t/calculating-eucledian-distance-between-two-tensors/85141\n",
    "            query_to_clses = None\n",
    "            for i in query_feature:\n",
    "                i = i.view(1,-1)\n",
    "                # parametric function\n",
    "                reg = None\n",
    "                for j in support_feature:\n",
    "                    dis = dist(i*j)\n",
    "\n",
    "                    if reg is not None:\n",
    "                        reg =torch.cat((reg,dis), 0)\n",
    "                    else:\n",
    "                        reg = dis\n",
    "                reg = reg.view(1,-1)\n",
    "\n",
    "                # cosine similarity\n",
    "                # reg = -F.cosine_similarity(support_feature,i).view(1,-1)\n",
    "\n",
    "                # Euclidean distance\n",
    "                # reg = ((support_feature - i)**2).sum(1).view(1,-1)\n",
    "\n",
    "                if query_to_clses is not None:\n",
    "                    query_to_clses = torch.cat((query_to_clses, reg), 0)\n",
    "                else:\n",
    "                    query_to_clses = reg\n",
    "\n",
    "            query_softmin = F.softmin(query_to_clses,dim=1)\n",
    "\n",
    "            loss = criterion(query_softmin, query_label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_ = len(query_to_clses)\n",
    "            total += total_\n",
    "\n",
    "            # TODO: classify the query data depending on the its distense with each prototype\n",
    "            correct_ = query_to_clses.argmin(dim=1).eq(query_label).sum().item()\n",
    "            correct += correct_\n",
    "            train_loss += loss\n",
    "            episodic_acc.append(correct_/total_)\n",
    "\n",
    "        episodic_acc = np.array(episodic_acc)\n",
    "        mean = episodic_acc.mean()\n",
    "        std = episodic_acc.std()\n",
    "    \n",
    "        print(f'Epoch:{ep+1}\\tAccuracy: {mean * 100:.2f} +- { 1.96 * std / (600)**(1/2) * 100:.2f} %\\tLoss:{loss:.4f}')\n",
    "        predict_1_3(model)\n",
    "        \n",
    "        torch.save(model, f'cspth/cs_{ep}_{mean * 100:.4f}.pth')\n",
    "        \n",
    "        train_acc_his.append(mean * 100)\n",
    "        train_loss_his.append(loss)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    with torch.no_grad():\n",
    "        ans = None\n",
    "        model.eval()\n",
    "        # each batch represent one episode (support data + query data)\n",
    "        for i, (data, target) in enumerate(tqdm(val_loader)):\n",
    "            # split data into support and query data\n",
    "            support_input = data[:val_N_way * val_K_shot,:,:,:] \n",
    "            query_input   = data[val_N_way * val_K_shot:,:,:,:]\n",
    "\n",
    "            # create the relative label (0 ~ N_way-1) for query data\n",
    "            label_encoder = {target[i * val_K_shot] : i for i in range(val_N_way)}\n",
    "            query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[val_N_way * val_K_shot:]])\n",
    "\n",
    "            # TODO: extract the feature of support and query data\n",
    "            # shape:torch.Size([N-way*K-shot, 1600]) torch.Size([N-way*N-query, 1600])\n",
    "            support_feature = model(support_input.to(device))\n",
    "            query_feature = model(query_input.to(device))\n",
    "            support_feature = support_feature.view(val_N_way,val_K_shot,1600).mean(dim=1)\n",
    "\n",
    "            # TODO: calculate the prototype for each class according to its support data\n",
    "            # ref:https://discuss.pytorch.org/t/calculating-eucledian-distance-between-two-tensors/85141\n",
    "            query_to_clses = None\n",
    "            for i in query_feature:\n",
    "                i = i.view(1,-1)\n",
    "                # parametric function\n",
    "                reg = None\n",
    "                for j in support_feature:\n",
    "                    dis = dist(i*j)\n",
    "\n",
    "                    if reg is not None:\n",
    "                        reg =torch.cat((reg,dis), 0)\n",
    "                    else:\n",
    "                        reg = dis\n",
    "                reg = reg.view(1,-1)\n",
    "\n",
    "                # cosine similarity\n",
    "                # reg = -F.cosine_similarity(support_feature,i).view(1,-1)\n",
    "\n",
    "                # Euclidean distance\n",
    "                # reg = ((support_feature - i)**2).sum(1).view(1,-1)\n",
    "\n",
    "                if query_to_clses is not None:\n",
    "                    query_to_clses = torch.cat((query_to_clses, reg), 0)\n",
    "                else:\n",
    "                    query_to_clses = reg\n",
    "\n",
    "\n",
    "            a = query_to_clses.argmin(dim=1).view(1,-1)\n",
    "            # TODO: classify the query data depending on the its distense with each prototype\n",
    "            if ans is not None:\n",
    "                ans = torch.cat((ans, a), 0)\n",
    "            else:\n",
    "                ans = a\n",
    "        pd.DataFrame(\n",
    "            ans.tolist(),\n",
    "            columns=[f'query{i}'for i in range(val_N_query*val_N_way)],\n",
    "        ).to_csv('out.csv', index_label='episode_id')\n",
    "        eval('out.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_1_3(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        ans = None\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        episodic_acc = []\n",
    "        model.eval()\n",
    "        # each batch represent one episode (support data + query data)\n",
    "        for i, (data, target) in enumerate(tqdm(val_loader)):\n",
    "            # split data into support and query data\n",
    "            support_input = data[:val_N_way * val_K_shot,:,:,:] \n",
    "            query_input   = data[val_N_way * val_K_shot:,:,:,:]\n",
    "\n",
    "            # create the relative label (0 ~ N_way-1) for query data\n",
    "            label_encoder = {target[i * val_K_shot] : i for i in range(val_N_way)}\n",
    "            query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[val_N_way * val_K_shot:]])\n",
    "\n",
    "            # TODO: extract the feature of support and query data\n",
    "            # shape:torch.Size([N-way*K-shot, 1600]) torch.Size([N-way*N-query, 1600])\n",
    "            support_feature = model(support_input.to(device))\n",
    "            query_feature = model(query_input.to(device))\n",
    "            support_feature = support_feature.view(val_N_way,val_K_shot,1600).mean(dim=1)\n",
    "\n",
    "            # TODO: calculate the prototype for each class according to its support data\n",
    "            # ref:https://discuss.pytorch.org/t/calculating-eucledian-distance-between-two-tensors/85141\n",
    "            query_to_clses = None\n",
    "            for i in query_feature:\n",
    "                i = i.view(1,-1)\n",
    "                reg = ((support_feature - i)**2).sum(1).view(1,-1)\n",
    "                if query_to_clses is not None:\n",
    "                    query_to_clses = torch.cat((query_to_clses, reg), 0)\n",
    "                else:\n",
    "                    query_to_clses = reg\n",
    "            \n",
    "            query_softmin = F.softmin(query_to_clses,dim=1)\n",
    "            loss = criterion(query_softmin, query_label)\n",
    "            total_ = len(query_to_clses)\n",
    "            total += total_\n",
    "            correct_ = query_to_clses.argmin(dim=1).eq(query_label).sum().item()\n",
    "            correct += correct_\n",
    "            val_loss += loss\n",
    "            episodic_acc.append(correct_/total_)\n",
    "            a = query_to_clses.argmin(dim=1).view(1,-1)\n",
    "            # TODO: classify the query data depending on the its distense with each prototype\n",
    "            if ans is not None:\n",
    "                ans = torch.cat((ans, a), 0)\n",
    "            else:\n",
    "                ans = a\n",
    "        episodic_acc = np.array(episodic_acc)\n",
    "        mean = episodic_acc.mean()\n",
    "        std = episodic_acc.std()\n",
    "    \n",
    "        print(f'-val-\\tAccuracy: {mean * 100:.2f} +- { 1.96 * std / (600)**(1/2) * 100:.2f} %\\tLoss:{loss:.4f}')\n",
    "        \n",
    "        val_acc_his.append(mean * 100)\n",
    "        val_loss_his.append(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(fn):\n",
    "    import csv\n",
    "\n",
    "    # read your prediction file\n",
    "    with open(fn, mode='r') as pred:\n",
    "        reader = csv.reader(pred)\n",
    "        next(reader, None)  # skip the headers\n",
    "        pred_dict = {int(rows[0]): np.array(rows[1:]).astype(int) for rows in reader}\n",
    "\n",
    "    # read ground truth data\n",
    "    with open('hw4_data/mini/val_testcase_gt.csv', mode='r') as gt:\n",
    "        reader = csv.reader(gt)\n",
    "        next(reader, None)  # skip the headers\n",
    "        gt_dict = {int(rows[0]): np.array(rows[1:]).astype(int) for rows in reader}\n",
    "\n",
    "    episodic_acc = []\n",
    "    for key, value in pred_dict.items():\n",
    "        episodic_acc.append((gt_dict[key] == value).mean().item())\n",
    "\n",
    "    episodic_acc = np.array(episodic_acc)\n",
    "    mean = episodic_acc.mean()\n",
    "    std = episodic_acc.std()\n",
    "\n",
    "    val_acc_his.append(mean * 100)\n",
    "    print('-Eval- Accuracy: {:.2f} +- {:.2f} %'.format(mean * 100, 1.96 * std / (600)**(1/2) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result():\n",
    "    plt.plot(train_acc_his)\n",
    "    plt.plot(val_acc_his)\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left') \n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(train_loss_his)\n",
    "    plt.plot(val_loss_his)\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left') \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convnet(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Convnet().to(device)\n",
    "print(model)\n",
    "# predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:35<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\tAccuracy: 34.54 +- 0.75 %\tLoss:1.4413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:43<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-val-\tAccuracy: 32.09 +- 0.62 %\tLoss:1.6515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:29<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2\tAccuracy: 40.00 +- 0.80 %\tLoss:1.3290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:36<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-val-\tAccuracy: 33.43 +- 0.67 %\tLoss:1.7179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:27<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3\tAccuracy: 43.46 +- 0.83 %\tLoss:1.3520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:28<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-val-\tAccuracy: 34.13 +- 0.68 %\tLoss:1.6378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:24<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4\tAccuracy: 46.35 +- 0.85 %\tLoss:1.3118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:18<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-val-\tAccuracy: 35.17 +- 0.69 %\tLoss:1.6231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:24<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5\tAccuracy: 48.75 +- 0.85 %\tLoss:1.2744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:15<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-val-\tAccuracy: 35.36 +- 0.69 %\tLoss:1.6780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:23<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6\tAccuracy: 51.01 +- 0.82 %\tLoss:1.2267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:08<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-val-\tAccuracy: 35.51 +- 0.68 %\tLoss:1.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:23<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7\tAccuracy: 52.78 +- 0.84 %\tLoss:1.2670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:04<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-val-\tAccuracy: 35.52 +- 0.70 %\tLoss:1.6503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:25<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8\tAccuracy: 54.44 +- 0.84 %\tLoss:1.2575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:10<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-val-\tAccuracy: 35.29 +- 0.68 %\tLoss:1.6246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:27<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9\tAccuracy: 55.78 +- 0.83 %\tLoss:1.2447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:11<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-val-\tAccuracy: 35.76 +- 0.69 %\tLoss:1.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 341/600 [01:21<01:02,  4.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22480/2195578431.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# model = torch.load('99_31.1567.pth')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplot_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22480/1483494229.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epoch)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msupport_feature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                     \u001b[0mdis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mreg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22480/2889543086.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# for i, layer in enumerate(self.layers):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m#     x = F.relu(layer(x)) if i < self.num_layers - 1 else layer(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_acc_his, train_loss_his = [], []\n",
    "val_acc_his, val_loss_his = [], []\n",
    "# model = torch.load('99_31.1567.pth')\n",
    "model = Convnet().to(device)\n",
    "train(model, 50)\n",
    "plot_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17916/2206563354.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_result' is not defined"
     ]
    }
   ],
   "source": [
    "plot_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06e30d277152b04c77de2258da9de4149228d00c6960d1c62da5d7e3583d03ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
